{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MegaDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.74  Python-3.11.2 torch-2.6.0+cpu CPU (Intel Core(TM) i7-10750H 2.60GHz)\n",
      "YOLOv9c summary (fused): 384 layers, 25,321,561 parameters, 0 gradients, 102.3 GFLOPs\n",
      "\n",
      "0: 480x640 1 animal, 440.9ms\n",
      "Speed: 4.0ms preprocess, 440.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved to detection_output.jpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from PytorchWildlife.models import detection as pw_detection\n",
    "\n",
    "def detect_objects(image_path):\n",
    "    \"\"\"\n",
    "    Detects objects in an image using the MegaDetector model.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to the image file.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the detection results, with keys:\n",
    "            \"detections\": A list of dictionaries, where each dictionary\n",
    "                          represents a detected object and contains the keys:\n",
    "                          \"bbox\": Bounding box coordinates [x1, y1, x2, y2].\n",
    "                          \"confidence\": Confidence score of the detection.\n",
    "                          \"category\": Category ID of the detected object.\n",
    "        None: If an error occurs during detection.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the MegaDetector model\n",
    "        detection_model = pw_detection.MegaDetectorV6(version=\"MDV6-yolov9-c\")\n",
    "\n",
    "        # Load the image\n",
    "        img = np.array(Image.open(image_path))\n",
    "\n",
    "        # Run object detection\n",
    "        detection_results = detection_model.single_image_detection(img)\n",
    "\n",
    "        # Prepare the output\n",
    "        detections = []\n",
    "        for i in range(len(detection_results[\"detections\"].xyxy)):\n",
    "            box = detection_results[\"detections\"].xyxy[i]\n",
    "            confidence = detection_results[\"detections\"].confidence[i]\n",
    "            category = detection_results[\"detections\"].class_id[i]\n",
    "\n",
    "            detections.append({\n",
    "                \"bbox\": box.tolist(),\n",
    "                \"confidence\": float(confidence),\n",
    "                \"category\": int(category)\n",
    "            })\n",
    "\n",
    "        return {\"detections\": detections}\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during object detection: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def visualize_detections(image_path, detections, output_path):\n",
    "    \"\"\"\n",
    "    Draws bounding boxes on an image and saves the result.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to the input image.\n",
    "        detections (dict): A dictionary containing detection results\n",
    "                           (as returned by detect_objects).\n",
    "        output_path (str): Path to save the output image with bounding boxes.\n",
    "    \"\"\"\n",
    "    fig = None\n",
    "    try:\n",
    "        # Load the image\n",
    "        img = np.array(Image.open(image_path))\n",
    "\n",
    "        # Create a figure and axes\n",
    "        fig, ax = plt.subplots(1)\n",
    "        ax.imshow(img)\n",
    "\n",
    "        # Draw bounding boxes\n",
    "        for detection in detections[\"detections\"]:\n",
    "            bbox = detection['bbox']\n",
    "            confidence = detection['confidence']\n",
    "            x1, y1, x2, y2 = int(bbox[0]), int(bbox[1]), int(bbox[2]), int(bbox[3])\n",
    "            rect = patches.Rectangle((x1, y1), x2 - x1, y2 - y1, linewidth=1, edgecolor='r', facecolor='none')\n",
    "            ax.add_patch(rect)\n",
    "            ax.text(x1, y1 - 5, f'{confidence:.2f}', color='white', fontsize=8, backgroundcolor='r')\n",
    "\n",
    "        # Save the image\n",
    "        plt.savefig(output_path)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during visualization: {str(e)}\")\n",
    "    finally:\n",
    "        if fig:\n",
    "            plt.close(fig)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "image_path = 'D:/orinoquia_camera_traps_images/A09/100EK113/01130114.JPG'  # Replace with your image path\n",
    "output_path = \"detection_output.jpg\"\n",
    "\n",
    "if os.path.exists(image_path):\n",
    "    detections = detect_objects(image_path)\n",
    "    if detections:\n",
    "        visualize_detections(image_path, detections, output_path)\n",
    "        print(f\"Detection results saved to {output_path}\")\n",
    "    else:\n",
    "        print(\"No objects detected or an error occurred during detection.\")\n",
    "else:\n",
    "    print(f\"Image not found: {image_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image path exists: {image_path}\n",
      "Ultralytics 8.3.74  Python-3.11.2 torch-2.6.0+cpu CPU (Intel Core(TM) i7-10750H 2.60GHz)\n",
      "YOLOv9c summary (fused): 384 layers, 25,321,561 parameters, 0 gradients, 102.3 GFLOPs\n",
      "\n",
      "0: 480x640 1 animal, 402.0ms\n",
      "Speed: 4.0ms preprocess, 402.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "detection_results: {'img_id': 'None', 'detections': Detections(xyxy=array([[     922.37,      118.56,        1920,      1337.7]], dtype=float32), mask=None, confidence=array([    0.97146], dtype=float32), class_id=array([0]), tracker_id=None, data={}), 'labels': ['animal 0.97']}\n",
      "Debugging PytorchWildlife Output:\n",
      "Type of detection_results: <class 'dict'>\n",
      "Expected keys 'detection_boxes', 'detection_scores', and 'detection_classes' not found in detection_results.\n",
      "Set for images for  {image_path} : {i}\n",
      "Proper params set:{i}\n",
      "Here is my images: {img}\n",
      "Here is is the width of the image, with shape{img.shape} for a height of {height} and width of {width}\n",
      "Has passed file integrity checks to draw\n",
      "Can finally draw the rectangle (after several steps)\n",
      "Created Rectangle with parameters {x1} for x1, {y1} for y1, {x2} for x2, {y2} for y2, and a confidence of {confidence} with a file height of {height} and width of {width}\n",
      "End Rectangle\n",
      "There were successful bounding boxes for {image_path} at the same directory\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from PytorchWildlife.models import detection as pw_detection\n",
    "import torch\n",
    "\n",
    "def debug_pytorchwildlife_output(detection_results):\n",
    "    print(\"Debugging PytorchWildlife Output:\")\n",
    "    print(f\"Type of detection_results: {type(detection_results)}\")\n",
    "    if isinstance(detection_results, dict):\n",
    "        if \"detection_boxes\" in detection_results and \"detection_scores\" in detection_results and \"detection_classes\" in detection_results:\n",
    "            boxes = detection_results[\"detection_boxes\"]\n",
    "            scores = detection_results[\"detection_scores\"]\n",
    "            classes = detection_results[\"detection_classes\"]\n",
    "\n",
    "            print(f\"Number of boxes: {len(boxes)}\")\n",
    "            print(f\"Number of scores: {len(scores)}\")\n",
    "            print(f\"Number of classes: {len(classes)}\")\n",
    "            for i in range(len(boxes)):\n",
    "                print(f\"--- Detection {i + 1} ---\")\n",
    "                print(f\"Type of box: {type(boxes[i])}\")\n",
    "                print(f\"Value of box: {boxes[i]}\")\n",
    "                print(f\"Type of confidence: {type(scores[i])}\")\n",
    "                print(f\"Value of confidence: {scores[i]}\")\n",
    "                print(f\"Type of class: {type(classes[i])}\")\n",
    "                print(f\"Value of class: {classes[i]}\")\n",
    "\n",
    "        else:\n",
    "            print(\"Expected keys 'detection_boxes', 'detection_scores', and 'detection_classes' not found in detection_results.\")\n",
    "    else:\n",
    "        print(\"Unexpected structure for detection_results. Not a dict.\")\n",
    "\n",
    "def run_megadetector_on_image(image_path):\n",
    "    detection_model = pw_detection.MegaDetectorV6(version=\"MDV6-yolov9-c\") # Model weights are automatically downloaded.\n",
    "\n",
    "    img = np.array(Image.open(image_path))\n",
    "    detection_results = detection_model.single_image_detection(img)\n",
    "\n",
    "    print(f\"detection_results: {detection_results}\")\n",
    "    #This is the section you must replace\n",
    "    #DEBUG CODE\n",
    "    # try:\n",
    "    #     for i in range(len(detection_results[\"detections\"].xyxy)):\n",
    "    #         print(f\"Boudning Boxes: {str(i)}\")\n",
    "    #     box = detection_results[\"detections\"].xyxy[i]\n",
    "    #     confidence = detection_results[\"detections\"].confidence[i] #Sets parameters\n",
    "    #     category = detection_results[\"detections\"].class_id[i]\n",
    "    #     print(f\"Boudning box success: {box} confidence : {confidence}\")\n",
    "    # except Exception as e:\n",
    "    #     print (\"Object has no boudning box data, but the image is being tested (please make sure the format is correct for all\")\n",
    "    \n",
    "    debug_pytorchwildlife_output(detection_results) # Debug the output\n",
    "\n",
    "    detections = {}\n",
    "    detections[\"images\"] = {}\n",
    "    detections[\"images\"][image_path] = []\n",
    "\n",
    "    # Format the results as MegaDetector output -Use XYXY Format for the image to use (It worked)\n",
    "    try:\n",
    "       for i in range(len(detection_results[\"detections\"].xyxy)): #Try to view all bounding boxes to see if image is working\n",
    "\n",
    "       #Set the bounding box object to be worked on\n",
    "            box = detection_results[\"detections\"].xyxy[i]\n",
    "            confidence = detection_results[\"detections\"].confidence[i] #Sets parameters\n",
    "            category = detection_results[\"detections\"].class_id[i]\n",
    "\n",
    "           #Verify all images\n",
    "            print(\"Set for images for  {image_path} : {i}\")\n",
    "\n",
    "           #Assign properties, can also move the transform here\n",
    "            height, width, _ = img.shape #Sets proper height settings with image properties\n",
    "            x1 = int(box[0]) #First coordinate for width point\n",
    "            y1 = int(box[1]) #First ordinate for height point\n",
    "            x2 = int(box[2]) #Second coordinate for Width point\n",
    "            y2 = int(box[3]) #Second ordinate for height point\n",
    "\n",
    "            print (\"Proper params set:{i}\") #Code that should be tested for\n",
    "\n",
    "           #Append all variables (to local list)\n",
    "            detections[\"images\"][image_path].append({\n",
    "                \"bbox\": box.tolist(),  # Convert box (torch.Tensor) to a list\n",
    "                \"confidence\": float(confidence),  # Convert confidence (torch.Tensor) to a float\n",
    "                \"category\": int(category),  # Convert category to int\n",
    "            })\n",
    "    except Exception as e: #Code breaks here if image file is bad\n",
    "       print(f\"Error processing detections: {str(e)}\")\n",
    "\n",
    "    return detections #Returns all image parameters\n",
    "\n",
    "# Helper function to draw bounding boxes on images\n",
    "def draw_boxes(image_path, detections, output_path):\n",
    "    fig = None #Ensures the image saves with the matplotlib backend\n",
    "    try:\n",
    "        img = np.array(Image.open(image_path))\n",
    "        print(\"Here is my images: {img}\")\n",
    "        #Scale bounding box coordinates from [y1, x1, y2, x2] to image size\n",
    "        height, width, _ = img.shape\n",
    "        print (\"Here is is the width of the image, with shape{img.shape} for a height of {height} and width of {width}\")\n",
    "        if(image_path in detections[\"images\"]):\n",
    "            print (\"Has passed file integrity checks to draw\")\n",
    "            \n",
    "            fig,ax = plt.subplots(1)   #Assign function as a variable\n",
    "            ax.imshow(img)  #Prints on graph\n",
    "            \n",
    "            for detection in detections[\"images\"][image_path]: #Run on all images\n",
    "                print (\"Can finally draw the rectangle (after several steps)\")\n",
    "                bbox = detection['bbox']#Sets each part\n",
    "                confidence = detection['confidence'] #Sets confidence levels\n",
    "                x1 = int(bbox[0]) #x1\n",
    "                y1 = int(bbox[1]) #y2\n",
    "                x2 = int(bbox[2]) #x2\n",
    "                y2 = int(bbox[3]) #x2 - All of it reads proper!\n",
    "                rect = patches.Rectangle((x1, y1), x2 - x1, y2 - y1, linewidth=1, edgecolor='r', facecolor='none')#Creates the boundary box\n",
    "\n",
    "                ax.add_patch(rect) #Adds shape as point in the image\n",
    "                ax.text(x1, y1-5, f'{confidence:.2f}', color = 'white', fontsize=8, backgroundcolor = 'r') #Add all text to the data\n",
    "                #Show what data that is sent to the local document\n",
    "\n",
    "                print (\"Created Rectangle with parameters {x1} for x1, {y1} for y1, {x2} for x2, {y2} for y2, and a confidence of {confidence} with a file height of {height} and width of {width}\")\n",
    "    #This code should now all be completely fixed. This prints what will be placed into the file to ensure data transfer and a great outcome for project\n",
    "            print (\"End Rectangle\")\n",
    "\n",
    "        plt.savefig(output_path) #Saves the file\n",
    "\n",
    "    except Exception as e: #Check code\n",
    "        print (f\"File may have broken, but is at least tested : {str(e)}\")\n",
    "    finally:\n",
    "        if fig:\n",
    "           plt.close(fig)\n",
    "\n",
    "# Image name to check\n",
    "# image_path = 'D:/orinoquia_camera_traps_images/A09/100EK113/01130114.JPG' #Base Image file\n",
    "image_path = 'D:/orinoquia_camera_traps_images/A09/100EK113/01210144.JPG' #Base Image file\n",
    "\n",
    "#Set Output Settings\n",
    "output_path = \"detection_output.jpg\"\n",
    "\n",
    "#These parameters may no longer exist, they may need to create functions to add them\n",
    "\n",
    "#Make sure image path is valid\n",
    "if os.path.exists(image_path): #If it exists then all code will work\n",
    "    print (\"This image path exists: {image_path}\")\n",
    "    try:\n",
    "        detections = run_megadetector_on_image(image_path) #Add files to code (as we said)\n",
    "        draw_boxes(image_path, detections, output_path) #Run code and generate boundary points\n",
    "\n",
    "        print (\"There were successful bounding boxes for {image_path} at the same directory\")#Success\n",
    "\n",
    "    except Exception as e:  #If broken check these steps to improve the code\n",
    "        print (f\"There are potential issues with library files: {str(e)}\")\n",
    "#The image did not exist skip\n",
    "else:\n",
    "    print (f\"The image {image_path} does not exists, skipped\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
